{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd3adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde599db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset/blob/master/ethos/experiments/utilities/preprocess.py\n",
    "\n",
    "def my_clean(text, stops=False, stemming=False):\n",
    "    text = str(text)\n",
    "    text = re.sub(r\" US \", \" american \", text)\n",
    "    text = text.lower().split()\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"don't\", \"do not \", text)\n",
    "    text = re.sub(r\"aren't\", \"are not \", text)\n",
    "    text = re.sub(r\"isn't\", \"is not \", text)\n",
    "    text = re.sub(r\"%\", \" percent \", text)\n",
    "    text = re.sub(r\"that's\", \"that is \", text)\n",
    "    text = re.sub(r\"doesn't\", \"does not \", text)\n",
    "    text = re.sub(r\"he's\", \"he is \", text)\n",
    "    text = re.sub(r\"she's\", \"she is \", text)\n",
    "    text = re.sub(r\"it's\", \"it is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = text.lower().split()\n",
    "    text = [w for w in text if len(w) >= 2]\n",
    "    if stemming and stops:\n",
    "        text = [\n",
    "            word for word in text if word not in stopwords.words('english')]\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        englishStemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "        text = [englishStemmer.stem(word) for word in text]\n",
    "        text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "        text = [\n",
    "            word for word in text if word not in stopwords.words('english')]\n",
    "    elif stops:\n",
    "        text = [\n",
    "            word for word in text if word not in stopwords.words('english')]\n",
    "    elif stemming:\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        englishStemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "        text = [englishStemmer.stem(word) for word in text]\n",
    "        text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c9eb090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Ethos_Dataset_Binary.csv', sep=';')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ccdd9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>isHate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You should know women's sports are a joke</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You look like Sloth with deeper Down’s syndrome</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You look like Russian and speak like Indian. B...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Women deserve to be abused, I guess.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Women are made for making babies and cooking d...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  isHate\n",
       "0          You should know women's sports are a joke     1.0\n",
       "1    You look like Sloth with deeper Down’s syndrome     1.0\n",
       "2  You look like Russian and speak like Indian. B...     1.0\n",
       "3               Women deserve to be abused, I guess.     1.0\n",
       "4  Women are made for making babies and cooking d...     1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aebf1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comment'] = data.apply(my_clean, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d82ce85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>isHate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment you should know women sports are joke ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment you look like sloth with deeper down s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment you look like russian and speak like i...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment women deserve to be abused guess ishat...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment women are made for making babies and c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  isHate\n",
       "0  comment you should know women sports are joke ...     1.0\n",
       "1  comment you look like sloth with deeper down s...     1.0\n",
       "2  comment you look like russian and speak like i...     1.0\n",
       "3  comment women deserve to be abused guess ishat...     1.0\n",
       "4  comment women are made for making babies and c...     1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d11be857",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('Ethos_Dataset_Binary.csv', index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
